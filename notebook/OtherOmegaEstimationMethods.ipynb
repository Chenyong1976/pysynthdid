{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation of other estimation methods for omega\n",
    "- In this report, we try to estimate omega in a different way from the original paper and check AA-test result.\n",
    "- The `omega` is the weight of features (donor pull) in Synthetic Control Methods.\n",
    "- The classical Synthetic Control Methods (ADH) restrictions the following:\n",
    "    - non-negativity of weights\n",
    "    - summing to one\n",
    "    - no intercept\n",
    "- In the original paper, intercept is allowed for this. (It also incorporates the L2 regularization term into the loss function.)\n",
    "\n",
    "## Additional methods for PySynthDID\n",
    "### (1) Search zeta by cross validation\n",
    "- `zeta` is a hyper-parameter in the estimation of `omega`\n",
    "- In the original paper, theoretical values were used for zeta.\n",
    "- In this note, we do not use this theoretical value, but perform cross-validation in the pre-intervention period and compare and discuss the results.\n",
    "    - Grid Search\n",
    "    - Baysian Optimaization\n",
    "\n",
    "### (2) Significant relaxation of ADH conditions\n",
    "- While the ADH condition is very good in terms of interpretability, it does not seem to be particularly necessary mathematically.\n",
    "- Here, we relax the `sum(w)=1 condition` and the `non-negative constraint`. Specifically, we adopt Lasso, Rige, and ElasticNet, and after performing CV, we adopt the coefficients of sparse regression as `omega`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import spearmanr\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from synthdid.model import SynthDID\n",
    "from synthdid.sample_data import fetch_CaliforniaSmoking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fetch_CaliforniaSmoking()\n",
    "\n",
    "PRE_TEREM = [1970, 1988]\n",
    "POST_TEREM = [1989, 2000]\n",
    "\n",
    "TREATMENT = [\"California\"]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdid = SynthDID(df, PRE_TEREM, POST_TEREM, TREATMENT)\n",
    "sdid.fit(zeta_type=\"base\", sparce_estimation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eg.\n",
    "sdid.estimated_params(model=\"ElasticNet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Search zeta by cross validation\n",
    "- No particular performance improvement was observed\n",
    "- Considering the cost of cross-validation, we believe that the choice of theoretical values in the original paper is reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TEREM2 = [1970, 1979]\n",
    "POST_TEREM2 = [1980, 1988]\n",
    "\n",
    "_sdid = SynthDID(df, PRE_TEREM2, POST_TEREM2, TREATMENT)\n",
    "\n",
    "print (\"zeta with original\")\n",
    "_sdid.fit(zeta_type=\"base\")\n",
    "\n",
    "_outcome = pd.DataFrame({\"actual_y\": _sdid.target_y()})\n",
    "\n",
    "_outcome[\"did\"] = _sdid.did_potentical_outcome()\n",
    "_outcome[\"sc\"] = _sdid.sc_potentical_outcome()\n",
    "_outcome[\"sdid\"] = _sdid.sdid_potentical_outcome()\n",
    "print(\"original zeta : \", _sdid.zeta)\n",
    "\n",
    "print (\"zeta with grid_search\")\n",
    "_sdid.fit(zeta_type=\"grid_search\", cv=3, cv_split_type=\"TimeSeriesSplit\", n_candidate=10)\n",
    "_outcome[\"sdid_grid_search\"] = _sdid.sdid_potentical_outcome()\n",
    "print(\"grid_search zeta : \", _sdid.zeta)\n",
    "\n",
    "print (\"zeta with bayesian optimaization\")\n",
    "_sdid.fit(zeta_type=\"bayesian_opt\", cv=3, cv_split_type=\"TimeSeriesSplit\")\n",
    "_outcome[\"sdid_bayesian_opt\"] = _sdid.sdid_potentical_outcome()\n",
    "print(\"bayesian_opt zeta : \", _sdid.zeta)\n",
    "\n",
    "_outcome = _outcome.loc[POST_TEREM2[0] : POST_TEREM2[1]]\n",
    "\n",
    "_rmse = np.sqrt((_outcome.mean() - _outcome.mean()[\"actual_y\"]) ** 2)\n",
    "pd.DataFrame(_rmse).T[\n",
    "    [\"did\", \"sc\", \"sdid\", \"sdid_grid_search\", \"sdid_bayesian_opt\"]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_list = df.columns\n",
    "\n",
    "result_rmse_list = []\n",
    "result_zeta_dict = {}\n",
    "\n",
    "for _state in tqdm(state_list):\n",
    "    _sdid = SynthDID(df, PRE_TEREM2, POST_TEREM2, [_state])\n",
    "    \n",
    "    _sdid.fit(zeta_type=\"base\")\n",
    "\n",
    "    _outcome = pd.DataFrame({\"actual_y\": _sdid.target_y()})\n",
    "\n",
    "    _outcome[\"did\"] = _sdid.did_potentical_outcome()\n",
    "    _outcome[\"sc\"] = _sdid.sc_potentical_outcome()\n",
    "    _outcome[\"sdid\"] = _sdid.sdid_potentical_outcome()\n",
    "    _base_zeta = _sdid.zeta\n",
    "    \n",
    "    print (\"zeta with bayesian optimaization\")\n",
    "    _sdid.fit(zeta_type=\"bayesian_opt\", cv=3, cv_split_type=\"TimeSeriesSplit\")\n",
    "    _outcome[\"sdid_bayesian_opt\"] = _sdid.sdid_potentical_outcome()\n",
    "    _cv_zeta = _sdid.zeta\n",
    "    \n",
    "    _outcome = _outcome.loc[POST_TEREM2[0] : POST_TEREM2[1]]\n",
    "\n",
    "    _rmse = np.sqrt((_outcome.mean() - _outcome.mean()[\"actual_y\"]) ** 2)\n",
    "    _rmse = pd.DataFrame(_rmse).T[\n",
    "        [\"did\", \"sc\", \"sdid\", \"sdid_bayesian_opt\"]\n",
    "    ]\n",
    "    _rmse.index = [_state]\n",
    "\n",
    "    result_rmse_list.append(_rmse)\n",
    "    result_zeta_dict[_state] = {\"base\" : _base_zeta, \"cv\" : _cv_zeta} \n",
    "    \n",
    "result_rmse = pd.concat(result_rmse_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result_zeta_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1) \n",
    "_x = np.linspace(0, 50, 30)\n",
    "_y = _x\n",
    "sns.scatterplot(data=result_rmse, x=\"sdid_bayesian_opt\", y=\"sdid\", ax = ax)\n",
    "ax.plot(_x, _y, color='black',  linestyle='solid',linewidth = 0.5)\n",
    "ax.set_xlabel(\"RMSE : Synthetic Diff. in Diff with zeta CV search\")\n",
    "ax.set_ylabel(\"RMSE : Synthetic Diff. in Diff with original zeta\")\n",
    "#ax.set_xlim(0, 25)\n",
    "#ax.set_ylim(0, 55)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_rmse.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## (2) Significant relaxation of ADH conditions\n",
    "- The AAtest results below confirm that the original Synthetic Diff. in Diff. has better performance then sdid with Lasso, Rige, and ElasticNet\n",
    "- This seems to be the assumption of the original paper. In the first place, SythDID has been developed to compensate for the shortcomings in classical SC because it concentrates on a specific donor pool and the results are not stable.\n",
    "- Among the sparce regressions, the Rigge regression performed better, and the Lasso regression is similar to the classical SC, which seems to be the assumption of the original paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_list = df.columns\n",
    "\n",
    "result_rmse_list = []\n",
    "\n",
    "for _state in tqdm(state_list):\n",
    "    _sdid = SynthDID(df, PRE_TEREM2, POST_TEREM2, [_state])\n",
    "    _sdid.fit(zeta_type=\"base\", sparce_estimation=True)\n",
    "\n",
    "    _outcome = pd.DataFrame({\"actual_y\": _sdid.target_y()})\n",
    "\n",
    "    _outcome[\"did\"] = _sdid.did_potentical_outcome()\n",
    "    _outcome[\"sc\"] = _sdid.sc_potentical_outcome()\n",
    "    _outcome[\"sdid\"] = _sdid.sdid_potentical_outcome()\n",
    "    _outcome[\"sdid_ElasticNet\"] = _sdid.sparceReg_potentical_outcome(model=\"ElasticNet\")\n",
    "    _outcome[\"sdid_Lasso\"] = _sdid.sparceReg_potentical_outcome(model=\"Lasso\")\n",
    "    _outcome[\"sdid_Ridge\"] = _sdid.sparceReg_potentical_outcome(model=\"Ridge\")\n",
    "    _outcome = _outcome.loc[POST_TEREM2[0] : POST_TEREM2[1]]\n",
    "\n",
    "    _rmse = np.sqrt((_outcome.mean() - _outcome.mean()[\"actual_y\"]) ** 2)\n",
    "    _rmse = pd.DataFrame(_rmse).T[\n",
    "        [\"did\", \"sc\", \"sdid\", \"sdid_ElasticNet\", \"sdid_Lasso\", \"sdid_Ridge\"]\n",
    "    ]\n",
    "    _rmse.index = [_state]\n",
    "\n",
    "    result_rmse_list.append(_rmse)\n",
    "    \n",
    "result_rmse = pd.concat(result_rmse_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_rmse.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
